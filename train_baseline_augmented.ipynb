{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"LUNGS2\" # DRIVE, CVC-ClinicDB, LUNGS2, ISIC2018, ISBI2012_EM, DSB2018\n",
    "CFG_NAME = \"Aug_Unet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import callbacks\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from imgaug import augmenters as iaa\n",
    "import models as M\n",
    "import losses as l\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"./\")\n",
    "DATASET_FOLDER = \"npys\"\n",
    "DATASET_PATH = os.path.join(ROOT_DIR, \"datasets\", DATASET_FOLDER)\n",
    "EXPERIMENT_NAME = \"{}_{}\".format(DATASET_NAME, CFG_NAME)\n",
    "\n",
    "if not os.path.exists(os.path.join(ROOT_DIR, \"logs\")):\n",
    "    os.mkdir(os.path.join(ROOT_DIR, \"logs\"))\n",
    "\n",
    "LOG_PATH = os.path.join(ROOT_DIR, \"logs\", EXPERIMENT_NAME)\n",
    "\n",
    "if not os.path.exists(LOG_PATH):\n",
    "    os.mkdir(LOG_PATH)\n",
    "    \n",
    "print(os.listdir(DATASET_PATH))\n",
    "\n",
    "train_data = np.load(\"{}/{}_images.npy\".format(DATASET_PATH, DATASET_NAME)) \n",
    "train_labels = np.load(\"{}/{}_mask.npy\".format(DATASET_PATH, DATASET_NAME))\n",
    "print(train_data.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard augment \n",
    "seq_standard = iaa.Sequential([\n",
    "    iaa.Crop(px=(0, 16)), \n",
    "    iaa.Fliplr(0.5), \n",
    "    iaa.Affine(\n",
    "        rotate=(-10, 10), # 25\n",
    "    ),\n",
    "    iaa.GaussianBlur(sigma=(0, 3.0))])\n",
    "\n",
    "# new augment\n",
    "seq_custom = iaa.Sequential([\n",
    "    iaa.ContrastNormalization((0.5, 1.5)),\n",
    "    iaa.Sometimes(0.5,\n",
    "        iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "    ),\n",
    "    iaa.Sometimes(0.7, \n",
    "        iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5)\n",
    "    ),\n",
    "    iaa.Affine(\n",
    "        rotate=(-25, 25),\n",
    "    ),\n",
    "    iaa.Affine(\n",
    "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "    ),\n",
    "    iaa.Affine(\n",
    "        shear=(-25, 25)\n",
    "    ),\n",
    "    \n",
    "    #iaa.Sometimes(0.8, \n",
    "     #   iaa.CoarseDropout(0.03, size_percent=0.1)\n",
    "    #),\n",
    "], random_order=True) # apply augmenters in random order\n",
    "\n",
    "\n",
    "def augment_data_minimal( x_values, y_values ):\n",
    "    counter = 0\n",
    "    RESIZE_DIM = x_values.shape[1]\n",
    "    RESIZE_DIM_ = x_values.shape[2]\n",
    "    channels = x_values.shape[-1]\n",
    "    X_values_augmented = []\n",
    "    Y_values_augmented = []\n",
    "    for x,y in zip(x_values, y_values):\n",
    "        for p in range(3):\n",
    "            \n",
    "            # seq 1\n",
    "            images_aug = seq_standard.augment_images(x.reshape(1,RESIZE_DIM,RESIZE_DIM_,channels))\n",
    "            masks_aug = seq_standard.augment_images(y.reshape(1,RESIZE_DIM,RESIZE_DIM_,1))\n",
    "            X_values_augmented.append( images_aug.reshape(RESIZE_DIM,RESIZE_DIM_,channels))\n",
    "            Y_values_augmented.append( masks_aug.reshape(RESIZE_DIM,RESIZE_DIM_,1))\n",
    "            \n",
    "            # seq 2\n",
    "            #Y_values_augmented.append( y_values[counter] )\n",
    "            #images_aug = seq_custom.augment_images(x.reshape(1,RESIZE_DIM,RESIZE_DIM,3))   \n",
    "            #X_values_augmented.append( images_aug.reshape(RESIZE_DIM,RESIZE_DIM,3))\n",
    "\n",
    "        counter = counter + 1\n",
    "    \n",
    "    \n",
    "    # prev number of images = n\n",
    "    # augmented number of images = n * 4 ( 2 seq 2 times)\n",
    "    X_values_augmented = np.asarray( X_values_augmented )\n",
    "    Y_values_augmented = np.asarray( Y_values_augmented )\n",
    "    return (X_values_augmented, Y_values_augmented)\n",
    "\n",
    "\n",
    "\n",
    "# Runtime data augmentation\n",
    "def get_train_test_augmented(X_train, Y_train, X_test, Y_test, batch_size=16, seed=42):\n",
    "   \n",
    "    # Image data generator distortion options\n",
    "    data_gen_args = dict(featurewise_center = False, \n",
    "                         samplewise_center = False,\n",
    "                         rotation_range=5.,\n",
    "                         width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,\n",
    "                         shear_range=0.2,\n",
    "                         zoom_range=0.2,\n",
    "                         horizontal_flip=True,\n",
    "                         vertical_flip=True,\n",
    "                         fill_mode='constant')\n",
    "    \n",
    "    \n",
    "    data_gen_args2 = dict(featurewise_center = False, \n",
    "                  samplewise_center = False,\n",
    "                  rotation_range = 5, \n",
    "                  width_shift_range = 0.01, \n",
    "                  height_shift_range = 0.01, \n",
    "                  shear_range = 0.01,\n",
    "                  zoom_range = [0.9, 1.1],  \n",
    "                  horizontal_flip = True, \n",
    "                  vertical_flip = True, # no upside down cars\n",
    "                  fill_mode = 'nearest',\n",
    "                  data_format = 'channels_last')\n",
    "    \n",
    "\n",
    "    # Train data, provide the same seed and keyword arguments to the fit and flow methods\n",
    "    X_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    Y_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    X_datagen.fit(X_train, augment=True, seed=seed)\n",
    "    Y_datagen.fit(Y_train, augment=True, seed=seed)\n",
    "    X_train_augmented = X_datagen.flow(X_train, batch_size=batch_size, shuffle=True, seed=seed)\n",
    "    Y_train_augmented = Y_datagen.flow(Y_train, batch_size=batch_size, shuffle=True, seed=seed)\n",
    "     \n",
    "    \n",
    "    # Test data, no data augmentation, but we create a generator anyway\n",
    "    X_datagen_val = ImageDataGenerator()\n",
    "    Y_datagen_val = ImageDataGenerator()\n",
    "    X_datagen_val.fit(X_test, augment=True, seed=seed)\n",
    "    Y_datagen_val.fit(Y_test, augment=True, seed=seed)\n",
    "    X_test_augmented = X_datagen_val.flow(X_test, batch_size=batch_size, shuffle=True, seed=seed)\n",
    "    Y_test_augmented = Y_datagen_val.flow(Y_test, batch_size=batch_size, shuffle=True, seed=seed)\n",
    "    \n",
    "    \n",
    "    # combine generators into one which yields image and masks\n",
    "    train_generator = zip(X_train_augmented, Y_train_augmented)\n",
    "    test_generator = zip(X_test_augmented, Y_test_augmented)\n",
    "    \n",
    "    return train_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(x_aug, y_aug) = augment_data_minimal( train_data, train_labels)\n",
    "#x_aug.shape, y_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_augmented = np.concatenate( (train_data, x_aug), axis = 0)\n",
    "#Y_train_augmented = np.concatenate( (train_labels, y_aug), axis = 0)\n",
    "#X_train_augmented.shape, Y_train_augmented.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import random \n",
    "#plt.figure(figsize=(20,20))\n",
    "#columns = 5\n",
    "#lower = 0\n",
    "#upper = 10 \n",
    "#for i in range(upper):\n",
    "#    ax = plt.subplot(upper / columns + 1, columns, i + 1)\n",
    "#    idx = random.randint(0, len(x_aug))\n",
    "#    #ax.set_title(y_aug[idx])\n",
    "#    plt.grid(False)\n",
    "#    plt.imshow(np.squeeze(x_aug[idx]), cmap='gray') # binary\n",
    "#\n",
    "#plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and save accuravy loss graphs individually\n",
    "def plot_loss_accu(history):\n",
    "    loss = history.history['loss'][1:]\n",
    "    val_loss = history.history['val_loss'][1:]\n",
    "    epochs = range(len(loss))\n",
    "    plt.plot(epochs, loss, 'g')\n",
    "    plt.plot(epochs, val_loss, 'y')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.ylabel('Loss %')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['training', 'validation'], loc='upper right')\n",
    "    plt.grid(True)\n",
    "    #plt.savefig('{}/{}_loss.jpg'.format(output_path, EXP_NAME), dpi=100)\n",
    "    plt.savefig('{}/{}_loss_graph.pdf'.format(LOG_PATH, EXPERIMENT_NAME), dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    loss = history.history['jacard'][1:]\n",
    "    val_loss = history.history['val_jacard'][1:]\n",
    "    epochs = range(len(loss))\n",
    "    plt.plot(epochs, loss, 'r')\n",
    "    plt.plot(epochs, val_loss, 'b')\n",
    "    plt.title('Training and validation jaccard index')\n",
    "    plt.ylabel('Accuracy %')\n",
    "    #plt.xlabel('Epoch')\n",
    "    plt.legend(['training', 'validation'], loc='lower right')\n",
    "    plt.grid(True)\n",
    "    #plt.savefig('{}/{}_acc.jpg'.format(output_path, EXP_NAME), dpi=100)\n",
    "    plt.savefig('{}/{}_jac_graph.pdf'.format(LOG_PATH, EXPERIMENT_NAME), dpi=100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "#model = M.g_unet(input_size = (train_data.shape[1], train_data.shape[2], train_data.shape[-1]))\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "weights_path = \"{}/{}.h5\".format(LOG_PATH, EXPERIMENT_NAME)\n",
    "checkpointer = ModelCheckpoint(filepath=weights_path, verbose=0, monitor='val_jacard', mode='max', save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_jacard', factor=0.1, patience=10, verbose=1, min_lr=1e-8, mode='max') # new_lr = lr * factor\n",
    "early_stopping = EarlyStopping(monitor='val_jacard', min_delta=0, verbose=1, patience=20, mode='max', restore_best_weights=True)\n",
    "csv_logger = CSVLogger('{}/{}_training.csv'.format(LOG_PATH, EXPERIMENT_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results from multiple runs\n",
    "jacs = []\n",
    "dices = []\n",
    "all_epochs = []\n",
    "losses = []\n",
    "\n",
    "best_jac = 0\n",
    "\n",
    "# Calculate the starting time    \n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    # Split the data\n",
    "    #x_train, x_test, y_train, y_test = train_test_split(train_data, train_labels, shuffle=True, test_size=0.20, random_state=42)\n",
    "    indices=list(range(len(train_data)))\n",
    "    np.random.shuffle(indices)\n",
    "    ind=int(len(indices)*0.80)\n",
    "    train = indices[:ind]\n",
    "    test = indices[-(len(indices)-ind):]\n",
    "\n",
    "    x_train = train_data[train]\n",
    "    x_test = train_data[test]\n",
    "    y_train = train_labels[train]\n",
    "    y_test = train_labels[test]\n",
    "    \n",
    "    # Augment data\n",
    "    (x_aug, y_aug) = augment_data_minimal( x_train, y_train)    \n",
    "    # Upsample data\n",
    "    x_train = np.concatenate( (x_train, x_aug), axis = 0)\n",
    "    y_train = np.concatenate( (y_train, y_aug), axis = 0)    \n",
    "    \n",
    "\n",
    "    print(\"Fold {} train on -------> \".format(i), x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "    \n",
    "    # Clearing the NN.\n",
    "    K.clear_session()\n",
    "    model = None \n",
    "    \n",
    "    # Define the model\n",
    "    model = M.unet(input_size = (train_data.shape[1], train_data.shape[2], train_data.shape[-1]))\n",
    "    \n",
    "    # Train\n",
    "    batch_size = 16 \n",
    "    epochs = 100000\n",
    "    \n",
    "    # Data genenrators\n",
    "    #train_generator, test_generator = get_train_test_augmented(x_train, y_train, x_test,\n",
    "    #                                                           y_test, batch_size=batch_size, seed=42)\n",
    "    #model.fit_generator(train_generator, validation_data=test_generator, validation_steps=batch_size/2,\n",
    "    #                    steps_per_epoch=len(x_train)/(batch_size * 2), epochs=epochs,\n",
    "    #                    callbacks=[early_stopping, reduce_lr],\n",
    "    #                    shuffle=True)\n",
    "    \n",
    "    \n",
    "    model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[early_stopping, reduce_lr],\n",
    "                    shuffle=True)\n",
    "    \n",
    "    \n",
    "    # Log number of epochs to train and minimum loss\n",
    "    total_epochs = len(model.history.history['loss'])\n",
    "    min_loss = min(model.history.history['val_loss'])\n",
    "    all_epochs.append(total_epochs)\n",
    "    losses.append(min_loss)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Evaluate trained model using Jaccard and Dice metric\n",
    "    yp = None\n",
    "    yp = model.predict(x=x_test, batch_size=batch_size, verbose=0)\n",
    "    yp = np.round(yp,0)\n",
    "\n",
    "    jacard = 0\n",
    "    dice = 0\n",
    "    \n",
    "    for i in range(len(y_test)):\n",
    "        yp_2 = yp[i].ravel()\n",
    "        y2 = y_test[i].ravel()\n",
    "\n",
    "        intersection = yp_2 * y2\n",
    "        union = yp_2 + y2 - intersection\n",
    "\n",
    "        jacard += (np.sum(intersection)/np.sum(union))  \n",
    "        dice += (2. * np.sum(intersection) ) / (np.sum(yp_2) + np.sum(y2))\n",
    "\n",
    "    jacard /= len(y_test)\n",
    "    dice /= len(y_test)\n",
    "\n",
    "    print('Jacard Index : '+str(jacard))\n",
    "    print('Dice Coefficient : '+str(dice))\n",
    "    \n",
    "    jacs.append(jacard)\n",
    "    dices.append(dice)\n",
    "    \n",
    "    #best_jac = max(jacs)\n",
    "    \n",
    "    if jacard > best_jac:\n",
    "        \n",
    "        print('***********************************************')\n",
    "        print('Jacard Index improved from '+str(best_jac)+' to '+str(jacard))\n",
    "        print('***********************************************')\n",
    "        # Save model\n",
    "        model.save(weights_path)\n",
    "        \n",
    "        # Save loss\n",
    "        loss_history = model.history.history[\"val_loss\"]\n",
    "        loss_history = np.array(loss_history)\n",
    "        np.savetxt(\"{}/{}_loss.txt\".format(LOG_PATH, EXPERIMENT_NAME), loss_history, delimiter=\",\")\n",
    "        \n",
    "        # Save jaccard\n",
    "        jacard_history = model.history.history[\"val_jacard\"]\n",
    "        jacard_history = np.array(jacard_history)\n",
    "        np.savetxt(\"{}/{}_jacard.txt\".format(LOG_PATH, EXPERIMENT_NAME), jacard_history, delimiter=\",\")\n",
    "        \n",
    "        # Save images, masks, and predicted masks\n",
    "        np.save(\"{}/{}_inputs.npy\".format(LOG_PATH, EXPERIMENT_NAME), x_test)\n",
    "        np.save(\"{}/{}_masks.npy\".format(LOG_PATH, EXPERIMENT_NAME), y_test)\n",
    "        np.save(\"{}/{}_predicted_masks.npy\".format(LOG_PATH, EXPERIMENT_NAME), yp)\n",
    "        \n",
    "        # Log training history\n",
    "        plot_loss_accu(model.history)\n",
    "        \n",
    "        final_images = x_test\n",
    "        final_masks = y_test\n",
    "        final_preds = yp\n",
    "        \n",
    "        best_jac = jacard\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"--- Time taken to train : %s hours ---\" % ((end_time - start_time)//3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacs = [x * 100 for x in jacs]\n",
    "dices = [x * 100 for x in dices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacs, dices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Jaccard: %.4f%% (+/- %.4f%%)\" % (np.mean(jacs), np.std(jacs)))\n",
    "print(\"Dice: %.4f%% (+/- %.4f%%)\" % (np.mean(dices), np.std(dices)))\n",
    "print(\"Epochs: %.4f%% (+/- %.4f%%)\" % (np.mean(all_epochs), np.std(all_epochs)))\n",
    "print(\"Loss: %.4f%% (+/- %.4f%%)\" % (np.mean(losses), np.std(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store report\n",
    "\n",
    "report = {}\n",
    "\n",
    "report['Mean Jaccard + Std = '] = (\"%.4f%% +/- %.4f%%\" % (np.mean(jacs), np.std(jacs)))\n",
    "report['Mean Dice + Std = '] = (\"%.4f%% +/- %.4f%%\" % (np.mean(dices), np.std(dices)))\n",
    "report['Mean Epoch + Std = '] = (\"%.4f%% +/- %.4f%%\" % (np.mean(all_epochs), np.std(all_epochs)))\n",
    "report['Mean Loss + Std = '] = (\"%.4f%% +/- %.4f%%\" % (np.mean(losses), np.std(losses)))\n",
    "\n",
    "with open(\"{}/{}_REPORT.txt\".format(LOG_PATH, EXPERIMENT_NAME), 'w') as f:\n",
    "    for k,v in report.items():\n",
    "        f.write(str(k))\n",
    "        #f.write(\"--->\")\n",
    "        f.write(str(v))\n",
    "        \n",
    "        # new line\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = loss_history\n",
    "j = jacard_history\n",
    "epochs = range(len(j))\n",
    "plt.plot(epochs, l, 'g')\n",
    "plt.plot(epochs, j, 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = final_images\n",
    "y_test = final_masks\n",
    "yp = final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs('{}/results/'.format(LOG_PATH, EXPERIMENT_NAME))\n",
    "except:\n",
    "    pass \n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.subplot(1,3,1)\n",
    "    if len(x_test[i].shape) >= 2:\n",
    "        plt.grid(False)\n",
    "        plt.imshow(x_test[i].squeeze(), cmap='gray') # 1-channel image\n",
    "    else:\n",
    "        plt.grid(False)\n",
    "        plt.imshow(x_test[i]) # 3-channel\n",
    "        \n",
    "    plt.title('Input')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(y_test[i].reshape(y_test[i].shape[0],y_test[i].shape[1]), cmap='magma')\n",
    "    plt.title('Ground Truth')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(yp[i].reshape(yp[i].shape[0],yp[i].shape[1]), cmap='magma')\n",
    "    plt.title('Prediction')\n",
    "    \n",
    "    # Calc jaccard index of predictions\n",
    "    intersection = yp[i].ravel() * y_test[i].ravel()\n",
    "    union = yp[i].ravel() + y_test[i].ravel() - intersection\n",
    "    jacard = (np.sum(intersection)/np.sum(union))  \n",
    "    \n",
    "    plt.suptitle('Jacard Index: '+ str(np.sum(intersection)) +'/'+ str(np.sum(union)) +' = '+str(jacard))\n",
    "    plt.savefig('{}/results/'.format(LOG_PATH, EXPERIMENT_NAME)+str(i)+'.png',format='png')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
